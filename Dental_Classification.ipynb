{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "name": "Dental Classification",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 9119256,
          "sourceType": "datasetVersion",
          "datasetId": 5504795
        }
      ],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Awais-mohammad/ADAS/blob/master/Dental_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "abbasseifossadat_dental_radiography_segmentation_path = kagglehub.dataset_download('abbasseifossadat/dental-radiography-segmentation')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "X97TXb1Evg5-"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: white; font-size:100%; text-align:left\">\n",
        "\n",
        "<h1 align=\"center\"><font color='#DAA520'>ðŸ’¡ Dental Radiograph Classification :</font></h1>\n",
        "    \n"
      ],
      "metadata": {
        "id": "sUeSB0Hhvg6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This document provides a comprehensive guide on a **dental image classification** project using deep learning. It covers the steps involved in _data preparation_, _model building_, _training_, and _evaluation_. The project employs TensorFlow and Keras to build and train a convolutional neural network (CNN) to classify dental radiographs into five categories: **Cavity, Fillings, Impacted Tooth, Implant, and Normal**. The guide includes code snippets for data augmentation, model architecture, and evaluation metrics, offering a detailed walkthrough of the entire machine-learning pipeline for dental image classification."
      ],
      "metadata": {
        "id": "hriaQbsEvg6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-success\">  \n",
        "    <h1 align=\"center\" style=\"color:darkgoldenrod;\">Data Preparation\n",
        "</h1>  \n",
        "     \n",
        "</div>"
      ],
      "metadata": {
        "id": "IDJI3aX_Xerl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Set the image size and batch size\n",
        "IMG_SIZE = (64, 64)\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "# Define the paths to the directories\n",
        "train_dir = '/kaggle/input/dental-radiography-segmentation/Dental_Radiography/train'\n",
        "valid_dir = '/kaggle/input/dental-radiography-segmentation/Dental_Radiography/valid'\n",
        "test_dir = '/kaggle/input/dental-radiography-segmentation/Dental_Radiography/test'\n",
        "\n",
        "# Data augmentation and normalization for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    # rotation_range=20,\n",
        "    # width_shift_range=0.2,\n",
        "    # height_shift_range=0.2,\n",
        "    # shear_range=0.2,\n",
        "    # zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Just rescaling for validation and testing\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow from directory for train, validation, and test sets\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "valid_data = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='sparse',\n",
        "    shuffle=False\n",
        ")\n",
        "# Check class indices\n",
        "print(\"Class Indices: \", train_data.class_indices)"
      ],
      "metadata": {
        "id": "UFnxLOJrXfHN",
        "outputId": "a1c8c2ab-f0e1-4b1c-9ef3-d17d95f40ed0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-01T07:20:29.820509Z",
          "iopub.execute_input": "2025-01-01T07:20:29.82088Z",
          "iopub.status.idle": "2025-01-01T07:21:04.968202Z",
          "shell.execute_reply.started": "2025-01-01T07:20:29.820851Z",
          "shell.execute_reply": "2025-01-01T07:21:04.966752Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-01-01 07:20:32.389843: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-01-01 07:20:32.389982: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-01-01 07:20:32.591222: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Found 25136 images belonging to 5 classes.\nFound 2812 images belonging to 5 classes.\nFound 1649 images belonging to 5 classes.\nClass Indices:  {'Cavity': 0, 'Fillings': 1, 'Impacted Tooth': 2, 'Implant': 3, 'Normal': 4}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-success\">  \n",
        "    <h1 align=\"center\" style=\"color:darkgoldenrod;\">handling Imbalanced Class\n",
        "</h1>  \n",
        "     \n",
        "</div>"
      ],
      "metadata": {
        "id": "oUz8FrwgYD-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract class labels from training data\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_data.classes),\n",
        "    y=train_data.classes\n",
        ")\n",
        "\n",
        "class_weights = dict(enumerate(class_weights))\n"
      ],
      "metadata": {
        "id": "Fug1s4D7YA_9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-success\">  \n",
        "    <h1 align=\"center\" style=\"color:darkgoldenrod;\">Model Architecture and Training\n",
        "</h1>  \n",
        "     \n",
        "</div>"
      ],
      "metadata": {
        "id": "cZ9ekm2IYP53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "\n",
        "inp = Input(shape=(*IMG_SIZE, 3))\n",
        "\n",
        "# First convolutional block\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(inp)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# Second convolutional block\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# Third convolutional block\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "\n",
        "# Flatten the output\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Fully connected layer\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Output layer\n",
        "out = Dense(5, activation='softmax')(x)\n",
        "\n",
        "# Model definition\n",
        "model = Model(inputs=inp, outputs=out)\n",
        "\n",
        "my_callbacks = [\n",
        "    EarlyStopping(min_delta=0.0001, monitor='loss', patience=15),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=15),\n",
        "    ModelCheckpoint(filepath='best_model.keras', monitor='val_loss', save_best_only=True)\n",
        "]\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "TMngUb_iYSsF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "51KyBieZ2Qju"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Model fitting\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=100,\n",
        "    validation_data=valid_data,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=my_callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "0LSoENhzYf3W"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-success\">  \n",
        "    <h1 align=\"center\" style=\"color:darkgoldenrod;\">Loading the Model\n",
        "</h1>  \n",
        "     \n",
        "</div>"
      ],
      "metadata": {
        "id": "r_oC13PM2eI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best saved model\n",
        "best_model = tf.keras.models.load_model('best_model.keras')"
      ],
      "metadata": {
        "id": "yaC_kaEh2gCj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-success\">  \n",
        "    <h1 align=\"center\" style=\"color:darkgoldenrod;\">Model Evaluation\n",
        "</h1>  \n",
        "     \n",
        "</div>"
      ],
      "metadata": {
        "id": "zshhJotrY_WI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot loss and val_loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "# Plot accuracy and val_accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MJwPhNAgZDxn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Evaluate and predict using the best model\n",
        "def evaluate_and_report(model, data, data_type='Validation'):\n",
        "    preds = model.predict(data)\n",
        "    pred_classes = np.argmax(preds, axis=1)\n",
        "    true_classes = data.classes\n",
        "\n",
        "    # Print classification report\n",
        "    report = classification_report(true_classes, pred_classes, target_names=data.class_indices.keys())\n",
        "    print(f'{data_type} Classification Report:\\n', report)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    cm = confusion_matrix(true_classes, pred_classes)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=data.class_indices.keys())\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(f'Confusion Matrix for {data_type} Data')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "KPl8AGj722lS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on validation data\n",
        "evaluate_and_report(best_model, valid_data, data_type='Validation')"
      ],
      "metadata": {
        "id": "f3CBxk3N3LNN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test data\n",
        "evaluate_and_report(best_model, test_data, data_type='Test')"
      ],
      "metadata": {
        "id": "ABWn9Sx-3NAc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Predict the classes for the test data\n",
        "test_preds = model.predict(test_data)\n",
        "test_pred_classes = np.argmax(test_preds, axis=1)\n",
        "test_true_classes = test_data.classes\n",
        "\n",
        "\n",
        "# Display 30 random images from the test data with actual and predicted labels\n",
        "fig, axes = plt.subplots(6, 5, figsize=(20, 20))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax in axes:\n",
        "    idx = random.randint(0, len(test_data.filenames) - 1)\n",
        "    img = plt.imread(os.path.join(test_dir, test_data.filenames[idx]))\n",
        "    ax.imshow(img)\n",
        "    true_label = list(test_data.class_indices.keys())[test_true_classes[idx]]\n",
        "    pred_label = list(test_data.class_indices.keys())[test_pred_classes[idx]]\n",
        "    ax.set_title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B8PufC0pZRrU"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}